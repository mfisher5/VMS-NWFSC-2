---
title: "Fisher Behavioral Clustering"
author: "Owen Liu"
date: "2/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(here)
library(NbClust)

# ggplot theme
plot_theme <-   theme_minimal()+
  theme(text=element_text(family="sans",size=10,color="black"),
        legend.text = element_text(size=14),
        axis.title=element_text(family="sans",size=14,color="black"),
        axis.text=element_text(family="sans",size=8,color="black"),
        panel.grid.major = element_line(color="gray50",linetype=3))
theme_set(plot_theme)
```

## Purpose

The goal of this analysis is to perform a clustering analysis on a suite of behavioral metrics describing the 2009-2018 west coast Dungeness crab fishing fleet. The metrics have been compiled based on fish ticket and VMS data, and include information on:

1.  Port use: Number of ports visited per month, average ports visited per trip, Shannon diversity index of port use
2.  Revenue: Mean Dungeness revenue per trip, SD revenue per trip
3.  Trip Length: Days per trip, distance per trip, SD days per trip, SD distance per trip
4.  Exploration: Mean cumulative choice entropy
5.  Mobility: Home range
6.  Risk-taking: Propensity to fish in high winds
7.  Derby fishing: Mean day-of-season of 90% annual catch reached
8.  Participation in other fisheries: percent of revenue from non-DCRB fisheries

All metrics (to the extent data allow) were calculated for each vessel and crab season.

## Import Data

```{r}
dat <- read_rds(here::here('fishing behavior','fishing_behavior_metrics_vessel_season.rds'))
glimpse(dat)
```

## Check collinearity

Let's look at the variables and see if any are highly correlated

```{r}
vars.corrs <- dat %>% select(-(1:2)) %>% 
  cor(use="complete.obs") %>% 
  as_tibble(rownames="var1") %>% 
  pivot_longer(-var1,names_to = "var2",values_to = "corr")
glimpse(vars.corrs)

```

There are some correlated variables, but not too many are greater than 0.7. Fishing trip mean and SD, and revenue per trip mean and SD, are all correlated with each other. Addtionally, the trip distance metrics are correlated with our measure of location choice entropy.

We remove SD trip distance and SD revenue for the following analyses.

## Re-scale variables

We want to re-scale variables to a 0 to 1 scale to avoid clustering artifacts caused simply by scale differences between variables.

```{r}
dat_scaled <- dat %>% 
  select(-trip_dist_sd,-revenue_sd) %>% 
  mutate_at(-(1:2),~./max(.,na.rm=T))
```

## Do Clustering

```{r}
dat_clust <- dat_scaled %>% select(-(1:2)) %>% NbClust(method="ward.D2",min.nc = 3,max.nc=10,index='all')
```

## Explore Clustering

`NbClust` calculates a number of different indices to try to determine the relevant number of clusters in a dataset. By majority rule (most indices), 3 is proposed as the best number of clusters (between 3 and 10).

```{r}
dat_clust$All.index %>% as.tibble(rownames="n_clust")
dat_clust$All.CriticalValues
dat_clust$Best.partition %>% length()
```

Apply the majority-rule partitions to the dataset

```{r}
library(factoextra)
library(viridis)
dat_clustered <- dat_scaled %>% na.omit() %>% 
  mutate(partition=dat_clust$Best.partition) %>% 
  as_tibble()

dat_nolabs <- dat_scaled %>% na.omit() %>% select(-(1:2))

# calc distances
dat.d <- dat_scaled %>% na.omit() %>% select(-(1:2)) %>% get_dist()

# calc clustering
dat.ward <- dat.d %>% hclust(method="ward.D2")

dat.pca <- FactoMineR::PCA(dat_nolabs)

# factoextra::fviz_dend(dat.hclust,k=4,palette=viridis_pal()(4),show_labels=FALSE,rect=T,rect_lty=2)
summary(dat.pca)
```
### Plot PCA with Groups

```{r}
# pca.inds <- dat.pca$ind$coord %>% as_tibble() %>% mutate(partition=dat_clust$Best.partition) %>% mutate(partition=factor(partition))
# glimpse(pca.inds)
# pca.vars <- dat.pca$var$coord %>% as_tibble() %>% mutate(lab=colnames(dat_nolabs))
# glimpse(pca.vars)

fviz_pca(dat.pca,geom.ind="point",
         col.ind=dat_clust$Best.partition %>% as.factor,
         col.var='black',addEllipses=TRUE,
         palette=viridis_pal()(3),alpha.ind=0.6)

```


## Variable Importance

Use `randomForest` to perform supervised classification and see which variables contribute most to classification

```{r}
library(randomForest)
rf <- randomForest(x=dat_nolabs,y=as.factor(dat_clust$Best.partition),importance = TRUE,ntree=1000)
var_imp <- rf$importance %>% as_tibble(rownames="variable") %>% 
  select(variable,MeanDecreaseAccuracy) %>% 
  mutate(rel_imp=MeanDecreaseAccuracy*100)
var_imp %>% 
  arrange(desc(rel_imp)) %>% 
  mutate(varname=factor(variable,levels=variable)) %>% 
  ggplot(aes(varname,rel_imp))+
  geom_col()+
  scale_y_continuous(breaks=seq(0,10,by=2))+
  labs(x="Variable",y="Relative Importance")+
  theme(axis.text.x = element_text(angle=90))
```

We can also look at distribution of variable values across groups

```{r,fig.height=8,fig.width=8}
library(multcompView)
find_multcompletters <- function(df){
  aovtemp <- aov(df,formula = value~partition)
  tukeyhsd <- TukeyHSD(aovtemp)
  multcompLetters(tukeyhsd$partition[,4])$Letters %>% 
    enframe(name='partition',value='letter') %>% 
    mutate(partition=as.factor(partition))
}
group_means <- dat %>% 
  select(-trip_dist_sd,-revenue_sd,-drvid,-crab_season) %>% 
  na.omit() %>% 
  mutate(partition=dat_clust$Best.partition %>% as.factor()) %>% 
  pivot_longer(-partition,names_to='variable',values_to = 'value') %>% 
  group_by(variable) %>% 
  nest() %>% 
  mutate(plotvars=purrr::map2(variable,data,function(j,k){
    labels=find_multcompletters(k)
    k %>%
      left_join(labels,by='partition') %>% 
      ggplot(aes(factor(partition),value,fill=factor(partition)))+
      geom_boxplot(col='gray50')+
      geom_text(aes(partition,y=(max(value)-min(value))*0.9+min(value),label=letter),check_overlap = T,nudge_x=-0.15,size=4)+
      scale_fill_manual(values=viridis_pal()(3))+
      labs(y="",x="",title=j)+
      guides(fill='none')
  })) %>% 
  ungroup()

library(cowplot)

plot_grid(plotlist=group_means$plotvars,labels=LETTERS[1:nrow(group_means)])

```


